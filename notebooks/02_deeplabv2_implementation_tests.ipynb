{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Deeplabv2: implementation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from models.deeplabv2 import DeepLabV2\n",
    "from models.msc import MSC\n",
    "from addict import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictSemantic:\n",
    "    def __init__(self, labels_path='../data/labels_2.txt', model_path='../models_parameters/deeplab_orig_cocostuff164k_iter100k.pth', use_cuda=True):\n",
    "        self._config = Dict(yaml.load(open('../config/cocostuff164k.yaml')))\n",
    "        self._device = self.get_device(use_cuda)\n",
    "        self.classes = self.generate_classes(labels_path)\n",
    "        self._model = self.setup_model(model_path, len(self.classes), train=True)\n",
    "        self._map_to_merged = self._add_merged_stuff()\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def get_device(use_cuda=True):\n",
    "        cuda = use_cuda and torch.cuda.is_available()\n",
    "        device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "        if cuda:\n",
    "            current_device = torch.cuda.current_device()\n",
    "            print(\"Device:\", torch.cuda.get_device_name(current_device))\n",
    "        else:\n",
    "            print(\"Device: CPU\")\n",
    "        return device\n",
    "\n",
    "    @staticmethod\n",
    "    def deeplabv2_resnet101_msc(n_classes):\n",
    "        return MSC(\n",
    "            base=DeepLabV2(n_classes=n_classes,\n",
    "                           n_blocks=[3, 4, 23, 3],\n",
    "                           atrous_rates=[6, 12, 18, 24]),\n",
    "            scales=[0.5, 0.75])\n",
    "    \n",
    "    def generate_classes(self, labels_path):\n",
    "        classes = {}\n",
    "        with open(labels_path) as f:\n",
    "            for label in f:\n",
    "                label = label.rstrip().split(\"\\t\")\n",
    "                classes[int(label[0])] = label[1].split(\",\")[0]\n",
    "        return classes\n",
    "\n",
    "    def setup_model(self, model_path, n_classes, train=True):\n",
    "        model = self.deeplabv2_resnet101_msc(n_classes=n_classes)\n",
    "        # if using last version of pytorch, can load only in GPU\n",
    "        # TODO: Need to fine tune the model on the last version of pytorch\n",
    "        # to be able to oad the model on the cpu\n",
    "        state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "        if train:\n",
    "            model.load_state_dict(state_dict, strict=False)  # to skip ASPP\n",
    "            return nn.DataParallel(model)\n",
    "        else:\n",
    "            model.load_state_dict(state_dict)\n",
    "            model = nn.DataParallel(model)\n",
    "            model.eval()\n",
    "            return model.to(self._device)\n",
    "\n",
    "    def _add_merged_stuff(self):\n",
    "        # This model was not trained with the new stuff-merged, so map manually\n",
    "        # using this string from http://cocodataset.org/#panoptic-eval\n",
    "        # Also set to \"VOID\" (-1) deleted stuff.\n",
    "        s = \"\"\"\\\n",
    "        tree-merged: branch, tree, bush, leaves\n",
    "        fence-merged: cage, fence, railing\n",
    "        ceiling-merged: ceiling-tile, ceiling-other\n",
    "        sky-other-merged: clouds, sky-other, fog\n",
    "        cabinet-merged: cupboard, cabinet\n",
    "        table-merged: desk-stuff, table\n",
    "        floor-other-merged: floor-marble, floor-other, floor-tile\n",
    "        pavement-merged: floor-stone, pavement\n",
    "        mountain-merged: hill, mountain\n",
    "        grass-merged: moss, grass, straw\n",
    "        dirt-merged: mud, dirt\n",
    "        paper-merged: napkin, paper\n",
    "        food-other-merged: salad, vegetable, food-other\n",
    "        building-other-merged: skyscraper, building-other\n",
    "        rock-merged: stone, rock\n",
    "        wall-other-merged: wall-other, wall-concrete, wall-panel\n",
    "        rug-merged: mat, rug, carpet\"\"\"\n",
    "        # Turn string into useful mapping\n",
    "        map_into_merged_int = {vv: idx + 183 for idx, (k, v) in enumerate(\n",
    "            x.split(\": \") for x in s.split(\"\\n\")) for vv in v.split(\", \")}\n",
    "        # Add mapping for delete stuff\n",
    "        map_into_merged_int.update({k: -1 for k in [\n",
    "            \"furniture-other\", \"metal\", \"plastic\", \"solid-other\",\n",
    "            \"structural-other\", \"waterdrops\", \"textile-other\", \"cloth\",\n",
    "            \"clothes\", \"plant-other\", \"wood\", \"ground-other\"]})\n",
    "\n",
    "        _inv = {v: k for k, v in self.classes.items()}\n",
    "        _map_to_merged = {_inv[k]: v for k, v in map_into_merged_int.items()}\n",
    "\n",
    "        extend_stuff_merged = {idx + 183: k for idx, (k, v) in enumerate(\n",
    "            x.split(\": \") for x in s.split(\"\\n\"))}\n",
    "        self.classes.update(extend_stuff_merged)\n",
    "        self.classes.update({-1: \"VOID\"})\n",
    "        return _map_to_merged\n",
    "\n",
    "    def _replace_labels_with_merged(self, labelmap):\n",
    "        # Simpler, just use pandas\n",
    "        return pd.DataFrame(labelmap).replace(self._map_to_merged).values\n",
    "\n",
    "    def _preprocess_one(self, img):\n",
    "        image = img.copy().astype(float)\n",
    "        scale = self._config.IMAGE.SIZE.TEST / max(image.shape[:2])\n",
    "        image = cv2.resize(image, dsize=None, fx=scale, fy=scale)\n",
    "        image -= np.array(\n",
    "            [\n",
    "                float(self._config.IMAGE.MEAN.B),\n",
    "                float(self._config.IMAGE.MEAN.G),\n",
    "                float(self._config.IMAGE.MEAN.R),\n",
    "            ]\n",
    "        )\n",
    "        return image.transpose(2, 0, 1)\n",
    "\n",
    "    def _preprocess_image(self, imgs):\n",
    "        buff = []\n",
    "        for img in imgs:\n",
    "            buff.append(self._preprocess_one(img))\n",
    "        image = torch.from_numpy(np.array(buff)).float()\n",
    "        return image.to(self._device)\n",
    "\n",
    "    def predict(self, img):\n",
    "        \"\"\"Predict on one image or batch\n",
    "        Return:\n",
    "            labelmap, labels\n",
    "        \"\"\"\n",
    "        if isinstance(img, np.ndarray) and img.ndim == 3:\n",
    "            return self._predict_batch([img])\n",
    "        return self._predict_batch(img)\n",
    "\n",
    "    def _predict_batch(self, imgs):\n",
    "        image = self._preprocess_image(imgs)\n",
    "        self._model.to(self._device)\n",
    "        output = self._model(image)\n",
    "        # 0.2s\n",
    "        output = F.interpolate(\n",
    "            output,\n",
    "            size=imgs[0].shape[:2],\n",
    "            mode=\"bilinear\", align_corners=True\n",
    "        )\n",
    "        output = F.softmax(output, dim=1)\n",
    "        output = output.data.cpu().numpy()\n",
    "\n",
    "        labelmaps = np.argmax(output, axis=1)\n",
    "        labelmaps = np.array([\n",
    "            self._replace_labels_with_merged(x) for x in labelmaps])\n",
    "        labels = np.array([np.unique(l) for l in labelmaps])\n",
    "        return labelmaps, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PredictSemantic(use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../data/test/000000000885.jpg')\n",
    "model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
