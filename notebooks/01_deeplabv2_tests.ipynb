{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) DeepLabv2 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from models.deeplabv2 import DeepLabV2\n",
    "from models.msc import MSC\n",
    "from addict import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepLabV2_ResNet101_MSC(n_classes):\n",
    "    return MSC(\n",
    "        base=DeepLabV2(n_classes=n_classes, \n",
    "                       n_blocks=[3, 4, 23, 3], \n",
    "                       atrous_rates=[6, 12, 18, 24]),\n",
    "        scales=[0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(use_cuda=True):\n",
    "    cuda = use_cuda and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "    if cuda:\n",
    "        current_device = torch.cuda.current_device()\n",
    "        print(\"Device:\", torch.cuda.get_device_name(current_device))\n",
    "    else:\n",
    "        print(\"Device: CPU\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(device, model_path, n_classes, train=True):\n",
    "    model = DeepLabV2_ResNet101_MSC(n_classes=n_classes)\n",
    "    # if using last version of pytorch, can load only in GPU\n",
    "    state_dict = torch.load(model_path, map_location=lambda storage, loc: storage) \n",
    "    if train:\n",
    "        model.load_state_dict(state_dict, strict=False)  # to skip ASPP\n",
    "        model = nn.DataParallel(model)\n",
    "    else:\n",
    "        model.load_state_dict(state_dict)\n",
    "        model = nn.DataParallel(model)\n",
    "        model.eval()\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_config = Dict(yaml.load(open('../config/cocostuff164k.yaml')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: GeForce GTX 1050 Ti with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "device = get_device(use_cuda=True)\n",
    "model = setup_model(device, \n",
    "                    '../models_parameters/deeplab_orig_cocostuff164k_iter100k.pth', \n",
    "                    182, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_merged_stuff(_classes):\n",
    "        # This model was not trained with the new stuff-merged, so map manually\n",
    "        # using this string from http://cocodataset.org/#panoptic-eval\n",
    "        # Also set to \"VOID\" (-1) deleted stuff.\n",
    "        s = \"\"\"\\\n",
    "        tree-merged: branch, tree, bush, leaves\n",
    "        fence-merged: cage, fence, railing\n",
    "        ceiling-merged: ceiling-tile, ceiling-other\n",
    "        sky-other-merged: clouds, sky-other, fog\n",
    "        cabinet-merged: cupboard, cabinet\n",
    "        table-merged: desk-stuff, table\n",
    "        floor-other-merged: floor-marble, floor-other, floor-tile\n",
    "        pavement-merged: floor-stone, pavement\n",
    "        mountain-merged: hill, mountain\n",
    "        grass-merged: moss, grass, straw\n",
    "        dirt-merged: mud, dirt\n",
    "        paper-merged: napkin, paper\n",
    "        food-other-merged: salad, vegetable, food-other\n",
    "        building-other-merged: skyscraper, building-other\n",
    "        rock-merged: stone, rock\n",
    "        wall-other-merged: wall-other, wall-concrete, wall-panel\n",
    "        rug-merged: mat, rug, carpet\"\"\"\n",
    "        # Turn string into useful mapping\n",
    "        map_into_merged_int = {vv: idx+183 for idx, (k, v) in enumerate(\n",
    "            x.split(\": \") for x in s.split(\"\\n\")) for vv in v.split(\", \")}\n",
    "        # Add mapping for delete stuff\n",
    "        map_into_merged_int.update({k: -1 for k in [\n",
    "            \"furniture-other\", \"metal\", \"plastic\", \"solid-other\",\n",
    "            \"structural-other\", \"waterdrops\", \"textile-other\", \"cloth\",\n",
    "            \"clothes\", \"plant-other\", \"wood\", \"ground-other\"]})\n",
    "\n",
    "        _inv = {v: k for k, v in _classes.items()}\n",
    "        _map_to_merged = {_inv[k]: v for k, v in map_into_merged_int.items()}\n",
    "\n",
    "        extend_stuff_merged = {idx+183: k for idx, (k, v) in enumerate(\n",
    "            x.split(\": \") for x in s.split(\"\\n\"))}\n",
    "        _classes.update(extend_stuff_merged)\n",
    "        _classes.update({-1: \"VOID\"})\n",
    "        \n",
    "        return _map_to_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_classes = {}\n",
    "with open('../data/labels_2.txt') as f:\n",
    "    for label in f:\n",
    "        label = label.rstrip().split(\"\\t\")\n",
    "        _classes[int(label[0])] = label[1].split(\",\")[0]\n",
    "_map_to_merged = _add_merged_stuff(_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _replace_labels_with_merged(_map_to_merged, labelmap):\n",
    "    # Simpler, just use pandas\n",
    "    return pd.DataFrame(labelmap).replace(_map_to_merged).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_one(img):\n",
    "    image = img.copy().astype(float)\n",
    "    scale = _config.IMAGE.SIZE.TEST / max(image.shape[:2])\n",
    "    image = cv2.resize(image, dsize=None, fx=scale, fy=scale)\n",
    "    image -= np.array(\n",
    "        [\n",
    "            float(_config.IMAGE.MEAN.B),\n",
    "            float(_config.IMAGE.MEAN.G),\n",
    "            float(_config.IMAGE.MEAN.R),\n",
    "        ]\n",
    "    )\n",
    "    return image.transpose(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_image(device, imgs):\n",
    "    buff = []\n",
    "    for img in imgs:\n",
    "        buff.append(_preprocess_one(img))\n",
    "    image = torch.from_numpy(np.array(buff)).float()\n",
    "    return image.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(device, model, img):\n",
    "    \"\"\"Predict on one image or batch\n",
    "    Return:\n",
    "        labelmap, labels\n",
    "    \"\"\"\n",
    "    if isinstance(img, np.ndarray) and img.ndim == 3:\n",
    "        return _predict_batch(device, model, [img])\n",
    "    return _predict_batch(device, model, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_batch(device, model, imgs):\n",
    "    # Note: it surprisingly does not speedup to run on bacthes\n",
    "    # TODO: check pytorch implem deeper and find why\n",
    "    image = _preprocess_image(device, imgs)\n",
    "    model.to(device)\n",
    "    output = model(image)\n",
    "    # 0.2s\n",
    "    output = F.interpolate(\n",
    "        output,\n",
    "        size=imgs[0].shape[:2],\n",
    "        mode=\"bilinear\", align_corners=True\n",
    "    )\n",
    "    output = F.softmax(output, dim=1)\n",
    "    output = output.data.cpu().numpy()\n",
    "\n",
    "    labelmaps = np.argmax(output, axis=1)\n",
    "    labelmaps = np.array([\n",
    "        _replace_labels_with_merged(_map_to_merged, x) for x in labelmaps])\n",
    "    labels = np.array([np.unique(l) for l in labelmaps])\n",
    "    return labelmaps, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../data/test/000000000885.jpg')\n",
    "device = get_device(use_cuda=False)\n",
    "predict(device, model, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works as expected, except that I cannot use it on a cpu because the pre-trained model was trained on a gpu on a different version of pytorch. I'll handle this later.   \n",
    "The next step is to implement this properly. Then I'll build the instance segmentation part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
